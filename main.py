import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama import OllamaLLM  # âœ… future-safe official import

# Streamlit UI
st.set_page_config(page_title="Gk Ai")
st.title("gk AI")

# Prompt template
template = """You are a helpful AI assistant.
Question: {question}
Answer: Let's think step by step."""

prompt = ChatPromptTemplate.from_template(template)

# âœ… Modern + No warning
model = OllamaLLM(model="deepseek-r1")  # requires `ollama list` to show deepseek-r1

# Chain
chain = prompt | model

# User input
question = st.chat_input("What's your question?")
if question:
    st.write("**Your Question:**", question)  # ðŸ‘ˆ yaha show hoga
    st.write(chain.invoke({"question": question}))
